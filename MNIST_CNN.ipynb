{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules and set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "BATCH_SIZE = 512\n",
    "EPOCHS = 30\n",
    "LEARNING_RATE = 0.01\n",
    "RANDOM_SEED = 42\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e:\\VSCODE\\Python\\DL-Hw\\MNIST\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "0\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "1\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "2\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "3\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "4\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "5\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "6\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "7\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "8\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "9\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "10\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "11\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "12\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "13\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "14\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "15\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "16\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "17\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "18\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "19\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "20\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "21\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "22\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "23\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "24\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "25\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "26\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "27\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "28\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "29\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "30\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "31\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "32\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "33\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "34\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "35\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "36\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "37\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "38\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "39\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "40\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "41\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "42\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "43\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "44\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "45\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "46\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "47\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "48\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "49\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "50\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "51\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "52\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "53\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "54\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "55\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "56\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "57\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "58\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "59\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "60\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "61\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "62\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "63\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "64\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "65\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "66\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "67\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "68\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "69\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "70\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "71\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "72\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "73\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "74\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "75\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "76\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "77\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "78\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "79\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "80\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "81\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "82\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "83\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "84\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "85\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "86\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "87\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "88\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "89\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "90\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "91\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "92\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "93\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "94\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "95\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "96\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "97\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "98\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "99\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "100\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "101\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "102\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "103\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "104\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "105\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "106\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "107\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "108\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "109\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "110\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "111\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "112\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "113\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "114\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "115\n",
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
      "116\n",
      "torch.Size([96, 1, 28, 28]) torch.Size([96])\n",
      "117\n"
     ]
    }
   ],
   "source": [
    "\n",
    "MNIST_PATH = os.path.join(os.getcwd(), \"MNIST\")\n",
    "print(MNIST_PATH)\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root=MNIST_PATH, train=True, download=True, transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ]))\n",
    "testset = torchvision.datasets.MNIST(root=MNIST_PATH, train=False, download=True, transform=transforms.Compose([\n",
    "                            transforms.ToTensor(),\n",
    "                            transforms.Normalize((0.1307,), (0.3081,))\n",
    "                          ]))\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "testloader = DataLoader(testset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "\n",
    "# print(len(trainset), len(testset))\n",
    "# print(trainset[0][0].shape)\n",
    "for batch_idx, (data, target) in enumerate(trainloader):\n",
    "    print(data.shape, target.shape)\n",
    "    # torch.Size([512, 1, 28, 28]) torch.Size([512])\n",
    "    # print(target)\n",
    "    # print(data[0][0])\n",
    "    print(batch_idx)\n",
    "\n",
    "\n",
    "\n",
    "# visualize some images\n",
    "\n",
    "\n",
    "X, y = next(iter(DataLoader(trainset, batch_size=18)))\n",
    "\n",
    "\n",
    "def get_labels(y):\n",
    "    return [trainset.classes[label] for label in y]\n",
    "\n",
    "\n",
    "def plot_images(images):\n",
    "    n_images = len(images)\n",
    "    rows = int(np.sqrt(n_images))\n",
    "    cols = int(np.sqrt(n_images))\n",
    "    fig = plt.figure()\n",
    "    for i in range(rows*cols):\n",
    "        ax = fig.add_subplot(rows, cols, i+1)\n",
    "        ax.imshow(images[i].numpy().squeeze(), cmap=\"gray_r\")\n",
    "        ax.set_title(get_labels(y)[i])\n",
    "        ax.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# plot_images(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (fc1): Linear(in_features=576, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n",
      "Model Summary:\n",
      "Layer: conv1.weight | Size: torch.Size([16, 1, 3, 3]) | Parameters: 144\n",
      "Layer: conv1.bias | Size: torch.Size([16]) | Parameters: 16\n",
      "Layer: conv2.weight | Size: torch.Size([32, 16, 3, 3]) | Parameters: 4608\n",
      "Layer: conv2.bias | Size: torch.Size([32]) | Parameters: 32\n",
      "Layer: conv3.weight | Size: torch.Size([64, 32, 3, 3]) | Parameters: 18432\n",
      "Layer: conv3.bias | Size: torch.Size([64]) | Parameters: 64\n",
      "Layer: fc1.weight | Size: torch.Size([256, 576]) | Parameters: 147456\n",
      "Layer: fc1.bias | Size: torch.Size([256]) | Parameters: 256\n",
      "Layer: fc2.weight | Size: torch.Size([10, 256]) | Parameters: 2560\n",
      "Layer: fc2.bias | Size: torch.Size([10]) | Parameters: 10\n",
      "Total Trainable Parameters: 173578\n"
     ]
    }
   ],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=1, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(64*3*3, 256)\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # input: 1x28x28\n",
    "        out = self.conv1(x)\n",
    "        out = F.relu(out)\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        # 16x14x14\n",
    "        out = self.conv2(out)\n",
    "        out = F.relu(out)\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        # 32x7x7\n",
    "        out = self.conv3(out)\n",
    "        out = F.relu(out)\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        # 64x3x3\n",
    "        out = out.view(-1, 64*3*3)\n",
    "        out = self.fc1(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = F.log_softmax(out, dim=1)\n",
    "        return out\n",
    "\n",
    "\n",
    "model = CNN().to(DEVICE)\n",
    "def print_model_summary(model):\n",
    "    print(model)\n",
    "    print(\"Model Summary:\")\n",
    "    total_params = 0\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            print(f\"Layer: {name} | Size: {param.size()} | Parameters: {param.numel()}\")\n",
    "            total_params += param.numel()\n",
    "    print(f\"Total Trainable Parameters: {total_params}\")\n",
    "\n",
    "print_model_summary(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No model found, training new model...\n"
     ]
    }
   ],
   "source": [
    "# check if there is pth file\n",
    "import re\n",
    "\n",
    "def save_model(model, path):\n",
    "    torch.save(model.state_dict(), path)\n",
    "    print(f\"Model saved at {path}\")\n",
    "\n",
    "def load_model(model, path):\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    print(f\"Model loaded from {path}\")\n",
    "\n",
    "def check_model(model, path):\n",
    "    if os.path.exists(path):\n",
    "        load_model(model, path)\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def get_latest_model(path):\n",
    "    Latest_Model = re.compile(r\"MNIST_CNN_(\\d+).pth\")\n",
    "    files = os.listdir(path)\n",
    "    latest_model = 0\n",
    "    for file in files:\n",
    "        match = Latest_Model.match(file)\n",
    "        if match:\n",
    "            epoch = int(match.group(1))\n",
    "            if epoch > latest_model:\n",
    "                latest_model = epoch\n",
    "    return latest_model\n",
    "\n",
    "\n",
    "MODEL_PATH = os.path.join(os.getcwd(), \"MNIST_CNN_\" + str(get_latest_model(os.getcwd())) + \".pth\")\n",
    "\n",
    "if check_model(model, MODEL_PATH):\n",
    "    print_model_summary(model)\n",
    "else:\n",
    "    print(\"No model found, training new model...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [14848/60000 (25%)]\tLoss: 0.473307\n",
      "Train Epoch: 1 [30208/60000 (50%)]\tLoss: 0.296076\n",
      "Train Epoch: 1 [45568/60000 (75%)]\tLoss: 0.145074\n",
      "\n",
      "Test set: Average loss: 0.0002, Accuracy: 9610/10000 (96%)\n",
      "\n",
      "Train Epoch: 2 [14848/60000 (25%)]\tLoss: 0.122137\n",
      "Train Epoch: 2 [30208/60000 (50%)]\tLoss: 0.065880\n",
      "Train Epoch: 2 [45568/60000 (75%)]\tLoss: 0.085639\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9813/10000 (98%)\n",
      "\n",
      "Train Epoch: 3 [14848/60000 (25%)]\tLoss: 0.059689\n",
      "Train Epoch: 3 [30208/60000 (50%)]\tLoss: 0.049851\n",
      "Train Epoch: 3 [45568/60000 (75%)]\tLoss: 0.050015\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9841/10000 (98%)\n",
      "\n",
      "Train Epoch: 4 [14848/60000 (25%)]\tLoss: 0.036984\n",
      "Train Epoch: 4 [30208/60000 (50%)]\tLoss: 0.063300\n",
      "Train Epoch: 4 [45568/60000 (75%)]\tLoss: 0.028789\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9867/10000 (99%)\n",
      "\n",
      "Train Epoch: 5 [14848/60000 (25%)]\tLoss: 0.059134\n",
      "Train Epoch: 5 [30208/60000 (50%)]\tLoss: 0.035618\n",
      "Train Epoch: 5 [45568/60000 (75%)]\tLoss: 0.035067\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9883/10000 (99%)\n",
      "\n",
      "Train Epoch: 6 [14848/60000 (25%)]\tLoss: 0.019212\n",
      "Train Epoch: 6 [30208/60000 (50%)]\tLoss: 0.030085\n",
      "Train Epoch: 6 [45568/60000 (75%)]\tLoss: 0.043846\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9878/10000 (99%)\n",
      "\n",
      "Train Epoch: 7 [14848/60000 (25%)]\tLoss: 0.031793\n",
      "Train Epoch: 7 [30208/60000 (50%)]\tLoss: 0.025008\n",
      "Train Epoch: 7 [45568/60000 (75%)]\tLoss: 0.015337\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9882/10000 (99%)\n",
      "\n",
      "Train Epoch: 8 [14848/60000 (25%)]\tLoss: 0.033202\n",
      "Train Epoch: 8 [30208/60000 (50%)]\tLoss: 0.024117\n",
      "Train Epoch: 8 [45568/60000 (75%)]\tLoss: 0.033225\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9913/10000 (99%)\n",
      "\n",
      "Train Epoch: 9 [14848/60000 (25%)]\tLoss: 0.026020\n",
      "Train Epoch: 9 [30208/60000 (50%)]\tLoss: 0.011821\n",
      "Train Epoch: 9 [45568/60000 (75%)]\tLoss: 0.039005\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9892/10000 (99%)\n",
      "\n",
      "Train Epoch: 10 [14848/60000 (25%)]\tLoss: 0.016790\n",
      "Train Epoch: 10 [30208/60000 (50%)]\tLoss: 0.031314\n",
      "Train Epoch: 10 [45568/60000 (75%)]\tLoss: 0.052176\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9883/10000 (99%)\n",
      "\n",
      "Model saved at e:\\VSCODE\\Python\\DL-Hw\\MNIST_CNN_10.pth\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# define learning strategy\n",
    "Loss = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# train model\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter(\"runs/BERT/\")\n",
    "\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        # loss = F.nll_loss(output, target)\n",
    "        loss = Loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if(batch_idx+1)%30 == 0: \n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            writer.add_scalar(\"Loss/train\", loss.item(), epoch*len(train_loader)+batch_idx)\n",
    "\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            # test_loss += F.nll_loss(output, target, reduction='sum').item() # 将一批的损失相加\n",
    "            test_loss += Loss(output, target).item()\n",
    "            pred = output.max(1, keepdim=True)[1] # 找到概率最大的下标\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    writer.add_scalar(\"Loss/test\", test_loss, epoch)\n",
    "    writer.add_scalar(\"Accuracy/test\", 100. * correct / len(test_loader.dataset), epoch)\n",
    "\n",
    "\n",
    "for epoch in range(1, 10 + 1):\n",
    "    train(model, DEVICE, trainloader, optimizer, epoch)\n",
    "    test(model, DEVICE, testloader)\n",
    "\n",
    "save_model(model, os.path.join(os.getcwd(), \"MNIST_CNN_\" + str(epoch) + \".pth\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
